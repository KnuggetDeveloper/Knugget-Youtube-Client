// Video 3: Marc Andreessen & Amjad Masad - Complete Transcripts
export const video3Transcripts = [
  {
    time: "0:00",
    text: "We're dealing with magic here that we I think probably all would have thought was impossible 5 years ago or certainly 10 years ago. This is the most amazing",
  },
  {
    time: "0:05",
    text: "technology ever and it's moving really fast and yet we're still like really disappointed. Like it's not moving fast enough and like it's like maybe right on",
  },
  {
    time: "0:11",
    text: "the verge of stalling out. We should both be like hyper excited but also on the verge of like slitting our wrists cuz like you know the gravy train is",
  },
  {
    time: "0:17",
    text: "coming to an end, right? It is faster but it's not at computer speed, right? What we expect computer",
  },
  {
    time: "0:22",
    text: "speed to be. It's sort of like watching a person work. It's like watching John Carmarmac",
  },
  {
    time: "0:28",
    text: "the world. Okay. the world's the world's best programmer on a stimulus. On a stimulant. Yeah, that's right.",
  },
  {
    time: "0:37",
    text: "So, let's start with um let's assume that I'm a sort of a novice programmer. So, maybe I'm a student um uh or maybe",
  },
  {
    time: "0:44",
    text: "I'm just somebody, you know, I took a few coding classes and I've hacked around a little bit or like I don't know, I do Excel macros or something",
  },
  {
    time: "0:49",
    text: "like that, but I'm like not less. I'm not like a master craftsman at coding. Um and you know people somebody tells me",
  },
  {
    time: "0:55",
    text: "about replet and and specifically AI um AI and Replet like what's my what's my experience uh when when I launch in with",
  },
  {
    time: "1:01",
    text: "with what replet is today with AI. Yeah I I would um I I think the experience of someone with no coding",
  },
  {
    time: "1:07",
    text: "experience or some coding experience is largely the same when you go into replet. Okay. The first thing we try to do is get all",
  },
  {
    time: "1:14",
    text: "the nonsense away from like setting up development environment and all of that stuff and just have you focus on your",
  },
  {
    time: "1:19",
    text: "idea. So what do you want to build? Do you want to build a product? Do you want to solve a problem? Do you want to do a",
  },
  {
    time: "1:24",
    text: "data vis visualization? So the prompt box is really open for you. You can put in anything there. So let's say you want",
  },
  {
    time: "1:30",
    text: "to, you know, build a startup. You have an idea for a startup. I would I would start with like a paragraph long kind of",
  },
  {
    time: "1:37",
    text: "description of what I want to build. Uh the agents will read that. It will you just type just type",
  },
  {
    time: "1:43",
    text: "standard English. Standard English. You just type it in. I want to build a I want to sell I want to sell crepes. I",
  },
  {
    time: "1:49",
    text: "want to sell crepes online. So you just like type in I want to talk. You can it literally could be that four",
  },
  {
    time: "1:55",
    text: "words or five words. Okay. Or it could be if you're if you have a programming language you prefer or stack",
  },
  {
    time: "2:00",
    text: "you prefer, you could do that. But we actually prefer not for you not to do that because we're going to pick the best thing for we're going to classify",
  },
  {
    time: "2:08",
    text: "the best stack for that request. Right? It's a if it's a data app, we'll pick Python and stream whatever. If it's like",
  },
  {
    time: "2:14",
    text: "a web app, we'll pick JavaScript and Postgress and things like that. So you just type that or you can decide you can decide you can",
  },
  {
    time: "2:20",
    text: "say and I want to do it I know Python or I'm learning Python in school and I want to do it in Python. That's right. The cool thing about",
  },
  {
    time: "2:25",
    text: "Replet is you know we we've been around for almost 10 years now and we built all this infrastructure. Replet runs any",
  },
  {
    time: "2:31",
    text: "programming language. So if you're comfortable with Python you can go in and do that for sure. Okay. And then just again I know this is",
  },
  {
    time: "2:37",
    text: "obvious people have used it but like I'm dealing in English. Yes. So okay go ahead.",
  },
  {
    time: "2:42",
    text: "Yes. You're fully in English. I mean, you know, just a, you know, a little bit of of sort of background here, like when",
  },
  {
    time: "2:49",
    text: "um when I I came here and pitched to you like 10 years ago or like whatever 7 years ago,",
  },
  {
    time: "2:55",
    text: "right? Uh what we were saying is we were exactly describing this future is that",
  },
  {
    time: "3:00",
    text: "uh everyone would want to build software, right? And the thing that's kind of getting in in people's ways is all the uh what Fred",
  },
  {
    time: "3:08",
    text: "Brooks called the accidental complexity of programming, right? They're like essential complexity which is like how",
  },
  {
    time: "3:13",
    text: "do I bring my startup to market and how do I build a business and all of that",
  },
  {
    time: "3:18",
    text: "accidental complexity is what package manager do I use all of that stuff we've been abstracting away that for so many",
  },
  {
    time: "3:24",
    text: "years so you can just um and the last thing we had to abstract away is code",
  },
  {
    time: "3:30",
    text: "right I had this realization last year which is I think we you know built an amazing",
  },
  {
    time: "3:35",
    text: "platform but the business is not performing and the reason the business is not performing is that code is the bottleneck like yes all the other stuff",
  },
  {
    time: "3:41",
    text: "is important to solve but syntax is still an issue like you know syntax is just an unnatural thing for people so",
  },
  {
    time: "3:48",
    text: "ultimately English is the programming language right I I just does it work with other other",
  },
  {
    time: "3:55",
    text: "world languages other than English at this point yes you can write in Japanese and we have a lot of users especially Japanese",
  },
  {
    time: "4:00",
    text: "that tends to be very so does it support these days like for a does a support every language or is it still do you still have to do like",
  },
  {
    time: "4:06",
    text: "custom work to craft a new new language no most most you know uh mainstream dream language that has like 100 million",
  },
  {
    time: "4:11",
    text: "plus people that speak it. AI is pretty good at it. Okay. Yeah. Yeah. Wow. So, uh I I I did a bit of a bit of",
  },
  {
    time: "4:18",
    text: "historical research recently for for some reason. I just want to just understand the moment we're in and because it's such a special moment. It's",
  },
  {
    time: "4:24",
    text: "I think it's important to contextualize it and I I I read this quote from",
  },
  {
    time: "4:30",
    text: "Gracehopper. So, Gracehopper invented the compiler as you know. uh at the time",
  },
  {
    time: "4:36",
    text: "people were uh you know programming in machine code and that's what programmers do that's what the specialists do",
  },
  {
    time: "4:42",
    text: "yes and she said you know specialists will always be a specialist they have to learn the underlying machinery of",
  },
  {
    time: "4:48",
    text: "computers but I want to get to a world where people are programming English that's what she said that's before",
  },
  {
    time: "4:53",
    text: "karpathy right that's like you know 75 years ago uh and and and that's why I invented the",
  },
  {
    time: "5:00",
    text: "compiler and in her mind like C programming is English right uh But that, you know, that really",
  },
  {
    time: "5:06",
    text: "didn't uh that was just the start of it. You had C and then you go higher level Python and JavaScript. And I think it",
  },
  {
    time: "5:13",
    text: "we're at a moment where it's the next step, right? Instead of typing syntax, you're",
  },
  {
    time: "5:18",
    text: "actually typing thoughts, you know, which is what we ultimately want. And the machine writes the code and the machine writes the code, right? Right.",
  },
  {
    time: "5:23",
    text: "Um yeah, I remember it. you're you're probably not old enough uh to remember but I I remember when when I was a kid it was um you know there there were were",
  },
  {
    time: "5:30",
    text: "higher level languages you know by the 70s like like basic and so forth and forran and C and C but um uh there were still",
  },
  {
    time: "5:36",
    text: "you know you still would run into people who were doing assembly programming assembly language which by the way you still do you know like game companies or",
  },
  {
    time: "5:42",
    text: "whatever still do assembly to to to get and they were hating on the kids that were doing basic. Oh well so so the assembly people were hating the kids",
  },
  {
    time: "5:47",
    text: "doing basic but there were also older coders who hated on the assembly programmers for doing assembly and not and not and not no no no not doing",
  },
  {
    time: "5:54",
    text: "direct machine code right not doing direct zero in one machine code because because as because assembly assembly so people don't know assembly language is",
  },
  {
    time: "6:00",
    text: "sort of this very low-level programming language that sort of compiles to actual actual machine code and if and if it's",
  },
  {
    time: "6:05",
    text: "it's it's incomprehensible gibberish to most program even most programmers you're writing an octal or something you're writing like very very close to",
  },
  {
    time: "6:10",
    text: "the hardware but even still it's still a language that compiles to zeros and ones um whereas the actual real programmers",
  },
  {
    time: "6:16",
    text: "actually wrote in zeros and ones. And so there there's always there's always this tendency, you know, for the for the for the pros to be, you know, look on the",
  },
  {
    time: "6:22",
    text: "nose. Yeah. And say, you know, the new people are being are being, you know, basically sloppy. They don't understand what's happening. You know, they don't really",
  },
  {
    time: "6:27",
    text: "understand the machine. And then, of course, you know, with with the higher level with the higher level abstractions do is they make they democratize. The",
  },
  {
    time: "6:33",
    text: "absolute irony is I was part of the JavaScript revolution. I was at Facebook uh before starting repled and we built",
  },
  {
    time: "6:40",
    text: "the modern JavaScript stack. We built ReactJS and all the tooling around it and we got a lot of hate from from the",
  },
  {
    time: "6:46",
    text: "programmers that you should type you know vanilla JavaScript directly and um I was like okay whatever and then",
  },
  {
    time: "6:53",
    text: "that you and now that's mainstream and then those guys that built their careers on the last wave we invented are hating",
  },
  {
    time: "6:59",
    text: "on this new wave and so just you know people never change. Okay, got it. Okay, so you you're typing English I want to",
  },
  {
    time: "7:05",
    text: "sell crepes online. I want to do this. I want to have a t-shirt. Whatever the business is. Okay. What what happens then? Yeah. and then uh uh replet agent will",
  },
  {
    time: "7:12",
    text: "show you what it understood. So it's trying to build um a common understanding between you and it and I",
  },
  {
    time: "7:19",
    text: "think there's a lot of things we can do better there in terms of UI but for now it'll show you a list of tasks.",
  },
  {
    time: "7:24",
    text: "It'll tell you I'm going to go set up a database because you need to store your data somewhere. Uh we need to set up",
  },
  {
    time: "7:30",
    text: "Shopify or Stripe because we need to accept payments. Uh and then it shows you this list and gives you two options",
  },
  {
    time: "7:36",
    text: "initially. Do you want to start with a design so that we can iterate back and forth to get lock that design down or do",
  },
  {
    time: "7:42",
    text: "you want to build a full thing? Hey, if you want to build a full thing, we'll go for 20, 30, 40 minutes.",
  },
  {
    time: "7:48",
    text: "Uh, and the a and be like the agent will tell you go here, install the app. Uh, I'm going to go set up the database,",
  },
  {
    time: "7:54",
    text: "do the migrations, write the SQL, you know, build the site. I'm going to also test it. So this is a recent innovation",
  },
  {
    time: "8:00",
    text: "we did with um agent 3 is that after it writes the software spins up a browser",
  },
  {
    time: "8:06",
    text: "goes around and tests in the browser and then any issue it kind of iterates kind of goes and fix the code. So it'll spend",
  },
  {
    time: "8:13",
    text: "20 30 minutes building that I'll send you a notification it'll tell you the app is ready. And so you can test it on your phone. You can go back to your",
  },
  {
    time: "8:18",
    text: "computer. You'll see maybe you'll find a bug or an issue, you'll describe it to the agent, say, \"Hey, it's not exactly",
  },
  {
    time: "8:25",
    text: "doing what I expected.\" Uh or if it's perfect and and you're ready to go and that's it. You know, 20 minutes. By the",
  },
  {
    time: "8:31",
    text: "way, there's a lot of examples where people just get their idea in 20 30 minutes, which is amazing. Um you just",
  },
  {
    time: "8:37",
    text: "hit publish. Mhm. You hit you hit publish. Um",
  },
  {
    time: "8:42",
    text: "couple clicks, you'll be up in the cloud. we'll set up a a virtual machine in the cloud. The database is deployed.",
  },
  {
    time: "8:49",
    text: "Everything's done and now you have a production database. So, think about the steps needed just two or 3 years ago in order to get to",
  },
  {
    time: "8:56",
    text: "that step. You have to set up your local development environment. You have to sign up for an AWS account. You have to provision the databases, the virtual",
  },
  {
    time: "9:02",
    text: "machines, you have to create the entire pip deployment pipeline. All of that is done for you. And it just, you know, a",
  },
  {
    time: "9:09",
    text: "kid can do it, a lay person can do it. If you're a programmer and uh you're",
  },
  {
    time: "9:14",
    text: "curious about what the agent did, the cool thing about replet because we have this history of being an IDE, you can",
  },
  {
    time: "9:19",
    text: "peel the layers. You can open the file tree and you could look at the files. You can open gits, you can push it to",
  },
  {
    time: "9:25",
    text: "GitHub, you can connect it to your editor if you want, you can open it in Emacs. So the cool thing about Replet, yes, it is a vibe coding platform that",
  },
  {
    time: "9:31",
    text: "abstracts away all the complexities, but all the layers are there for you to look at. Right. So let's go let's go back to um",
  },
  {
    time: "9:38",
    text: "that was great, but let's go back to you said it. It it gives you that the a the agent gives you you you say I've got my",
  },
  {
    time: "9:43",
    text: "idea. You plug it in and it says it gives you this list of things and then you and then when you describe it you said I'm going to do this. I'm going to do that. The eye there in that case was",
  },
  {
    time: "9:50",
    text: "the agent as opposed to the user. Yes. And so the the agent lists the set of things that it's going to do and then",
  },
  {
    time: "9:55",
    text: "the agent actually does those things. Agent does those things. Yeah. That that's a that's a that's a very important point. when we did this shift,",
  },
  {
    time: "10:03",
    text: "we hadn't realized internally at Replet how much the actual user stopped being the human user and it's actually the",
  },
  {
    time: "10:09",
    text: "agent programmer, right? So, one really uh funny thing happened is we had servers in Asia uh and we the",
  },
  {
    time: "10:16",
    text: "reason we had servers in Asia because we wanted our Indian or you know Japanese users to be to have a you know shorter",
  },
  {
    time: "10:23",
    text: "uh time to the servers. uh when we launched the agent their experience got",
  },
  {
    time: "10:28",
    text: "significantly worse and we're like what happened like it's supposed to be faster well turns out it's worse it's because the AIS are sitting in uh in United",
  },
  {
    time: "10:36",
    text: "States and so the the programmer is actually in United States it's you're sending the request to the programmer",
  },
  {
    time: "10:41",
    text: "and the programmer is interfacing with a machine across the world and so yes suddenly the agent is the programmer",
  },
  {
    time: "10:47",
    text: "okay so like the the ter ter you know new terminology agent is a software program that is basically using the rest",
  },
  {
    time: "10:54",
    text: "of the as if it were a as if it were a human user, but it's not. It's a it's a bot.",
  },
  {
    time: "10:59",
    text: "That's right. It has access to tools such as write a file, edit a file, delete a file, uh uh search the package",
  },
  {
    time: "11:06",
    text: "index, install a package, uh provision a database, provision object object storage. It is a programmer that has the",
  },
  {
    time: "11:13",
    text: "tools and interface. It has a sort of an interface that that is very similar to a human programmer. And then um you know we'll",
  },
  {
    time: "11:20",
    text: "talk more about how this all works but a debate inside the AI industry um is with these was kind of this you know this",
  },
  {
    time: "11:27",
    text: "idea now of having agents that do things on your behalf and then go out you know go go out and kind of accomplish missions. Um there's this you know kind",
  },
  {
    time: "11:32",
    text: "of debate which is okay how like obviously you know it's a big deal even to have an AI agent that can do relatively simple things to do complex",
  },
  {
    time: "11:38",
    text: "things of course is you know one of the great technical challenges of the last 80 years you know to to do that and then there's sort of this question of like",
  },
  {
    time: "11:44",
    text: "can the agent go out and run and operate on its own for 5 minutes you know for for 15 minutes for an hour for 8 hours",
  },
  {
    time: "11:50",
    text: "and and meaning like sort of like how long does it maintain coherence like how long does it actually like stay in full",
  },
  {
    time: "11:56",
    text: "control of it of its faculties and not kind of spin out because at least the early early agents or the the early AIS,",
  },
  {
    time: "12:01",
    text: "if if you set them off to do this, they might be able to run for two or three minutes, then they would they would start to get confused and go down rabbit holes and, you know, kind of kind of",
  },
  {
    time: "12:08",
    text: "spin out. Um, more recently, more recently, um, uh, you know, we've seen that that that that agents can run a lot",
  },
  {
    time: "12:13",
    text: "longer and and do more complex tasks. Like, where are we on the curve of agents being able to run for how long",
  },
  {
    time: "12:19",
    text: "and for what complexity tasks before before they break? That's that's absolutely the the I think the main metric we're looking at. even",
  },
  {
    time: "12:26",
    text: "back in 2023, you know, had the idea for software agents, you know, four or five years ago now. The problem every time we",
  },
  {
    time: "12:33",
    text: "attempt them, the the problem of coherence, you know, they'll they'll go on for a minute or two and then they'll",
  },
  {
    time: "12:39",
    text: "just, you know, they compound in errors in a way that they just can't recover. Um,",
  },
  {
    time: "12:44",
    text: "and you can actually see it, right? Because they actually they actually, if you watch watch them operate, they get increasingly confused and then, you",
  },
  {
    time: "12:49",
    text: "know, maybe even deranged. Yeah, they vary the range and they they go into very weird areas and sometimes they",
  },
  {
    time: "12:54",
    text: "start speaking Chinese and doing really weird things and um but I would say",
  },
  {
    time: "12:59",
    text: "sometime around last year we maybe crossed the 3 four five minute mark",
  },
  {
    time: "13:06",
    text: "and it felt to us that okay we're on a path where long re you know long horizon",
  },
  {
    time: "13:12",
    text: "reasoning is getting solved uh and so we made we made a bet and I I tell my team",
  },
  {
    time: "13:17",
    text: "so long horizon reasoning meaning reasoning meaning like dealing in like facts and logic",
  },
  {
    time: "13:23",
    text: "um in a in a sort of complex way and then long horizon being over a long period of time. Yes.",
  },
  {
    time: "13:29",
    text: "With many many steps to a reasoning process. Yeah, that's right. So if you think about the way large language models work is that they have a context. This",
  },
  {
    time: "13:36",
    text: "context is basically the memory all the text all your prompt and also all the internal talk that the AI is doing as",
  },
  {
    time: "13:42",
    text: "it's reasoning. So when the AI is reasoning it's actually talking to itself. It's like oh now I need to go set up a database. Well, what what kind",
  },
  {
    time: "13:49",
    text: "of tool do I have? Oh, there's a tool here that says Postgress. Okay, let me try using that. Okay, I use that. I got",
  },
  {
    time: "13:55",
    text: "feedback. Let me look at the feedback and read it. And it'll read the feedback. And so the that that prompt",
  },
  {
    time: "14:02",
    text: "box or context is where both the user input, the environment input, and the",
  },
  {
    time: "14:09",
    text: "internal thoughts of the machine are all within. It's sort of like a program memory in in memory space. And so",
  },
  {
    time: "14:15",
    text: "reasoning over that was the challenge for a long time. That's when AIs just like went off track and now they're able",
  },
  {
    time: "14:23",
    text: "to kind of think through this entire thing and and maintain coherence. And there's there's now techniques around uh",
  },
  {
    time: "14:30",
    text: "compression of contacts. So there still context length is still a problem, right? So I would say LM today, you",
  },
  {
    time: "14:38",
    text: "know, they're marketed as a million uh token uh length, which is like a million words almost. uh in reality it's about",
  },
  {
    time: "14:45",
    text: "200,000 and then they start to struggle. So we do a lot of uh you know we stop we",
  },
  {
    time: "14:50",
    text: "compress the memory. So if a memory if if a portion of the memory is saying that I'm getting all the logs from the",
  },
  {
    time: "14:56",
    text: "database you can summarize you know paragraphs of logs with one statement or the database setup that's it right and",
  },
  {
    time: "15:04",
    text: "so every once in a while we'll compress the context so that we make sure we maintain coherence so that there's a lot",
  },
  {
    time: "15:10",
    text: "of innovation happened outside of the foundation models as well in order to to enable that long context coherence. So",
  },
  {
    time: "15:16",
    text: "what was the what was the key technical breakthrough at the in the foundation models that made this possible do you think? I think it's RL I think it's uh",
  },
  {
    time: "15:22",
    text: "reinforcement learning. So the way pre-training works is you know uh they",
  },
  {
    time: "15:28",
    text: "uh pre-training is a uh the first step of training a large language model. It",
  },
  {
    time: "15:34",
    text: "reads a piece of text. It covers the last words and tries to guess it. That's how it's trained. That doesn't really",
  },
  {
    time: "15:41",
    text: "imply long context reasoning. it it you know it it turns out to be very very",
  },
  {
    time: "15:47",
    text: "effective. It can learn language that way. But the reason we weren't able to move past that limitation is that that",
  },
  {
    time: "15:55",
    text: "modality of training just wasn't good enough. And what you want is you want a",
  },
  {
    time: "16:00",
    text: "type of problem solving over a uh over long context. So what reinforcement",
  },
  {
    time: "16:05",
    text: "learning uh uh especially from code execution gave us is the ability to for",
  },
  {
    time: "16:12",
    text: "the machine to for the LLM to roll out what we call trajectories in AI. So",
  },
  {
    time: "16:18",
    text: "trajectory is a uh stepbystep reasoning chain in order to reach a solution. So",
  },
  {
    time: "16:25",
    text: "uh the way uh as I understand reinforcement learning works is they put the LM in a programming environment like",
  },
  {
    time: "16:32",
    text: "replet and say hey here's a pro here's a codebase here's a bug in the codebase",
  },
  {
    time: "16:38",
    text: "and we want you to solve it. Um now the human trainer already knows what the",
  },
  {
    time: "16:43",
    text: "solution would look like. So we have a pull request that we have on GitHub so we know exactly or we have a unit test that we can run and verify the solution.",
  },
  {
    time: "16:50",
    text: "So what it does is it rolls out a lot of different trajectories. Those they sample the model and maybe one of those",
  },
  {
    time: "16:56",
    text: "trajectories will reach and a lot of them will just go go off off track but one of them will reach the solution by",
  },
  {
    time: "17:03",
    text: "solving the bug and it reinforces on that. So that that gets a reward and the model gets trained that okay you know",
  },
  {
    time: "17:09",
    text: "this is how you solve these type of problems. So that's how we're able to extend these reasoning chains. Got it. and and how it's a two-part",
  },
  {
    time: "17:16",
    text: "question is how how how good how good are the models now at long long long",
  },
  {
    time: "17:21",
    text: "reasoning and and I would say and how do we know like how how is that established? Um",
  },
  {
    time: "17:27",
    text: "there is a nonprofit called meter um that is uh measuring",
  },
  {
    time: "17:34",
    text: "uh useful has a benchmark to measure uh how long a model runs while maintaining",
  },
  {
    time: "17:40",
    text: "coherence and doing useful useful things whether it's programming or other benchmark tasks that they've done. uh",
  },
  {
    time: "17:46",
    text: "and they put up a paper I think uh late last year that said every seven months",
  },
  {
    time: "17:52",
    text: "uh the the minutes that a model can run is doubling.",
  },
  {
    time: "17:58",
    text: "So you go from 2 minutes to you know 4 minutes in 7 months I think they vastly",
  },
  {
    time: "18:04",
    text: "underestimated that. Is that right? Vastly it's doubling. It's doubling more often than 7 months. We so Asian 3 we measure that you know",
  },
  {
    time: "18:11",
    text: "very closely uh and we measure that in real tasks from real users. So we're not",
  },
  {
    time: "18:16",
    text: "doing benchmarking. We're actually doing AB tests and we're looking at the data that how users are successful or not.",
  },
  {
    time: "18:21",
    text: "For us, the the absolute sign of success is you made an app and you published it. Because when you publish it, you're",
  },
  {
    time: "18:27",
    text: "paying extra money. You're saying this app is economically useful. I'm going to publish it. So that's as clear-cut as",
  },
  {
    time: "18:32",
    text: "possible. And so what we're seeing is in agent one, the agent could run for 2 minutes",
  },
  {
    time: "18:38",
    text: "and then and then perhaps struggle. Agent two came out in February, it ran for 20 minutes. Agent 3 200 minutes.",
  },
  {
    time: "18:45",
    text: "Okay, 200. Some users are pushing it to like 12 hours and things like that. I'm less",
  },
  {
    time: "18:50",
    text: "confident that it is as good and when it goes to these stratospheres, but at like",
  },
  {
    time: "18:56",
    text: "2 3 hours timeline, it is really it's it's it's it's insanely good. And and",
  },
  {
    time: "19:02",
    text: "the main innovation outside of the models is a verification loop. Actually,",
  },
  {
    time: "19:07",
    text: "uh I remember reading um a research paper from Nvidia. So what Nvidia did is",
  },
  {
    time: "19:12",
    text: "they're trying to uh write um GPU kernels uh using deepseek and that was",
  },
  {
    time: "19:18",
    text: "like perhaps 7 months ago when deepseek came out and what they found is that if we add a verifier in the loop if we can",
  },
  {
    time: "19:25",
    text: "run the kernel and verify it's working we're able to run deepseeek for like 20 minutes and it it was generating",
  },
  {
    time: "19:31",
    text: "actually optimized kernels and so I was like okay the next thing for us obviously as an as a sort of a",
  },
  {
    time: "19:39",
    text: "agent lab or like applay our company. We're not doing the foundation model",
  },
  {
    time: "19:44",
    text: "stuff, but we're doing a lot of research on top of that. And so, okay, we know that agents can run for 10 20 minutes",
  },
  {
    time: "19:50",
    text: "now or LLMs can stay coherent for longer, but for you to push them to 200,",
  },
  {
    time: "19:56",
    text: "300 minutes, you need a verifier in the loop. So, that's why we spend all our time uh creating scaffolds to make it so",
  },
  {
    time: "20:03",
    text: "that the agent can spin up a browser and do computer use style testing. So once",
  },
  {
    time: "20:08",
    text: "you put that in the middle, what's happening is it works for 20 minutes uh spin up another agent uh spins up a a",
  },
  {
    time: "20:16",
    text: "browser tests the work of the previous agent. So it's a multi- aent system and if it is uh if it founds a bug it",
  },
  {
    time: "20:24",
    text: "starts a new trajectory and says okay good work let's summarize what you did the last 20 minutes",
  },
  {
    time: "20:30",
    text: "now that be that plus what the bug that we found that's a prompt for a new trajectory right so you stack those on each other and you",
  },
  {
    time: "20:36",
    text: "can go endlessly but so it's like a mar like setting up a marathon or like a relay race as long as as long as each step is done",
  },
  {
    time: "20:42",
    text: "properly you could do in sort of an infinite number of steps that's right that's right you can always compress the previous step into a paragraph And that becomes a prompt. So",
  },
  {
    time: "20:49",
    text: "it's it's an agent prompting the next agent. Right. Right. Right. That's amazing. So um and then when when an agent like when",
  },
  {
    time: "20:54",
    text: "a modern agent like running on modern modern LM that are trained this way when it let's say it runs for 200 minutes like when you watch the agent run is it",
  },
  {
    time: "21:01",
    text: "like running is it like processing through like logic and tasks at the same pace that like a human being is or",
  },
  {
    time: "21:07",
    text: "slower or faster? I it's actually I would say it is faster",
  },
  {
    time: "21:12",
    text: "but not that much significantly faster. It's not at computer speed, right? What we expect computer speed to be.",
  },
  {
    time: "21:18",
    text: "It's like watching a per like if you watch if you if it's describing what it's doing, it's sort of like watching a person work. It's like watching John Carmarmacine",
  },
  {
    time: "21:26",
    text: "work. The world Okay. The world's the world's best programmer. Yeah. The world's best programmer on a stim on",
  },
  {
    time: "21:33",
    text: "a stimulant. On a stimulant. Yeah, that's right. Working for you. Working for you. Yeah. There. So, it's very fast and you",
  },
  {
    time: "21:39",
    text: "can see the uh file diffs running through, but every once in a while it'll stop and it'll start thinking. I'll show",
  },
  {
    time: "21:44",
    text: "you the reasoning. Yeah. It's like, I did this and I did this. Am I on the right track? It kind of really tries to reflect, right?",
  },
  {
    time: "21:50",
    text: "Uh and then it might review its work and decide the next step or it might kick into the testing agent or you know, so",
  },
  {
    time: "21:57",
    text: "so you're seeing it do all of that and every once in a while it calls the tool for example, it stops and says, well, we",
  },
  {
    time: "22:03",
    text: "ran into an issue. you know, Postgress um 15 is not um compatible with this,",
  },
  {
    time: "22:11",
    text: "you know, database ORM package that that I have. Um okay, this is a problem I haven't",
  },
  {
    time: "22:16",
    text: "seen before. I'm going to go search the web. So, it has a web search tool. Go do that. And so, it looks like a human",
  },
  {
    time: "22:22",
    text: "programmer, right? And it's really fascinating to watch. It's one of my favorite things to do is just to watch the tool chain and",
  },
  {
    time: "22:28",
    text: "reasoning chain and the testing chain. And it's yeah it is like watching a hyperproductive programmer",
  },
  {
    time: "22:34",
    text: "right so you know we're kind of getting into here kind of the holy grail of AI which is sort of you know generalized reasoning um you know by the machine um",
  },
  {
    time: "22:41",
    text: "so uh you mentioned this a couple times but this idea of a of a verification so so just for folks on the listening to",
  },
  {
    time: "22:48",
    text: "podcast who maybe aren't in the details let me try to describe this and see see if I have it right so like a just a just a large language model the way you would",
  },
  {
    time: "22:55",
    text: "exper you would have experienced with like Chad GPT out of the gate two years ago or whatever would have been it's like And it's incredible how fluid uh it",
  },
  {
    time: "23:01",
    text: "is at language. Um it's incredible how good it is at like writing Shakespearean sonnetss or rap lyrics. It's it's",
  },
  {
    time: "23:06",
    text: "amazing how good it is at human conversation. But if you start to ask it like problems that involve like rational thinking uh or problem solving all of a",
  },
  {
    time: "23:14",
    text: "sudden like you math or the math the whole show and and in the very beginning it was you could ask if you ask it very",
  },
  {
    time: "23:19",
    text: "basic math problems, you know, it would it would not be able to do them. That's right. Uh but then even when it got better at those, if you started to",
  },
  {
    time: "23:24",
    text: "ask it to like, you know, it it could maybe add two small numbers together, but it couldn't add two large numbers together. Or if it could add two large",
  },
  {
    time: "23:29",
    text: "numbers, it couldn't multiply them. Yeah. And it's just like, all right, this is And then it had this there was this famous the famous was the straw the",
  },
  {
    time: "23:35",
    text: "strawberry test, the famous strawberry test, which is how many Rs are in the word strawberry. That's right. And there was this long period where it it kept it would it would just guess",
  },
  {
    time: "23:41",
    text: "wrong. It would say there were only two Rs in the word strawberry. And it turns out there are three. Um, so, um, so it",
  },
  {
    time: "23:48",
    text: "it was this thing and so people were and there was even this term that was being used kind of the the slur that was being used at the time was stoastic parrot.",
  },
  {
    time: "23:54",
    text: "Yeah, I was thinking clanker. Well, well, clanker is the is the new slur. Clank clanker. Clanker is just the",
  },
  {
    time: "24:00",
    text: "full-on racial slur against AI as a species. Um, but the technical critique was so-called stoastic par stoastic",
  },
  {
    time: "24:07",
    text: "means random. Uh so sort of random parrot me meaning basically that this thing was sort of the large language models were like a they were like a",
  },
  {
    time: "24:13",
    text: "mirage where they were like repeating back to you things that they thought that you wanted to hear but they didn't in a way it's true in the in the pure",
  },
  {
    time: "24:19",
    text: "pre-training LLM world right for the for the very basic layer but then what happened is as you said over the last year or something there",
  },
  {
    time: "24:24",
    text: "there was this layering in of of reinforcement learning and then but the key to it's not new crucially it's like it's",
  },
  {
    time: "24:30",
    text: "alpha go right so describe so describe that for a second. Yeah. So we we had this breakthrough before in uh 2015 was the Alph Go",
  },
  {
    time: "24:39",
    text: "breakthrough. I think 2015 2016 where it is emerging of sort of uh you know the",
  },
  {
    time: "24:45",
    text: "the the you would know a lot better than me the old AI debate between the connectionists uh the the people who who",
  },
  {
    time: "24:52",
    text: "thinks neuronet networks are the true sort of way of doing AI and the symbolic systems I think or like the people that",
  },
  {
    time: "24:59",
    text: "think that you know discrete reasonings fates and knowledge bases whatever this is the way to go and so there was there",
  },
  {
    time: "25:05",
    text: "was a merging of these two worlds where the way AlphaG go worked is it had a neural network but it had a Monte Carlo",
  },
  {
    time: "25:12",
    text: "research algorithm on top of that. So the neural network would generate uh would would like uh generate a list of",
  },
  {
    time: "25:18",
    text: "potential moves uh and then you had a more discrete algorithm sort those moves",
  },
  {
    time: "25:23",
    text: "and find the best based on just uh tree search based on just trying to verify",
  },
  {
    time: "25:29",
    text: "again this sort of a verifier in the loop trying to verify which move might",
  },
  {
    time: "25:34",
    text: "yield the best based on more classical way of doing algorithms. Um, and so that",
  },
  {
    time: "25:40",
    text: "that's a resurgence of of that movement where we have this amazing generative uh",
  },
  {
    time: "25:46",
    text: "neural network that is the the LLM and now let's layer on more discrete ways of",
  },
  {
    time: "25:52",
    text: "trying to verify whether it's doing the right thing or not and let's put that in a training loop and once you do that the",
  },
  {
    time: "25:57",
    text: "LLM will start gaining new capabilities such as uh reasoning over math and code",
  },
  {
    time: "26:02",
    text: "and things like that. Exactly. Right. Okay. And then that's great. And then and then the the key thing there though for for RL to work",
  },
  {
    time: "26:07",
    text: "for LMS to reason the key is that it be a a problem statement that there is a",
  },
  {
    time: "26:12",
    text: "defined and verifiable answer. That's right. Is that right? And so and and and you might think about this as like let's",
  },
  {
    time: "26:18",
    text: "give a bunch of examples like in medicine this might be like um you know a diagnosis that like a panel of human doctors agrees with um or or or by the",
  },
  {
    time: "26:24",
    text: "way or a diagnosis that actually you know solves the condition. Um in law this would be a um you know a a argument",
  },
  {
    time: "26:31",
    text: "that in front of a jury actually results in an acquitt or or something like that. Um in u math it's an equation that",
  },
  {
    time: "26:37",
    text: "actually solves properly. Uh in physics it's a result that actually works in the real world. I don't know in civil engineering it's a",
  },
  {
    time: "26:42",
    text: "bridge that doesn't collapse. Right. So so so there there there's always some some test is that the first two do not",
  },
  {
    time: "26:49",
    text: "work very well just yet. like the the like I would say uh law and healthcare",
  },
  {
    time: "26:56",
    text: "they're still a little too squishy a little too soft it's unlike math or code",
  },
  {
    time: "27:01",
    text: "like the way that they're training on math they're using this uh sort of like a program language uh provable language",
  },
  {
    time: "27:06",
    text: "called lean for proofs right so you can run a lean statement you can run a computer code uh perhaps you can run a",
  },
  {
    time: "27:13",
    text: "physics simulation or civil engineering uh sort of physics simulation but you can't run a diagnosis",
  },
  {
    time: "27:19",
    text: "okay So I would say the but you could verify it with human answers or or not. Yeah. So that that's a more RL HF in a",
  },
  {
    time: "27:26",
    text: "way. So it is not the like sort of autonomous RL train like fully scalable",
  },
  {
    time: "27:32",
    text: "autonomous which is why coding is moving faster than any other domain is because",
  },
  {
    time: "27:37",
    text: "we can we we can generate these problems and verify them on the fly. But there's",
  },
  {
    time: "27:42",
    text: "two but with coding as anybody who's coded knows there's coding there's two tests which is one is does the code compile right and then the other is does it produce",
  },
  {
    time: "27:48",
    text: "the right output and just because it compiles doesn't mean it produces the right output and I you tell me but verifying that it's the correct output",
  },
  {
    time: "27:54",
    text: "is harder yeah sobbench is a collection of uh verified pull",
  },
  {
    time: "28:02",
    text: "request end state uh so so it is it is not just about compiling we so they they",
  },
  {
    time: "28:09",
    text: "group of scientists sobbench is the main benchmark used to test whether AI is",
  },
  {
    time: "28:14",
    text: "good at software engineering tasks and we're almost saturating that. So last year we're at like maybe 5% early 24 or",
  },
  {
    time: "28:23",
    text: "less and now we're like 82% or something like that with cloth on at 4.5 that's state-of-the-art and that's like a",
  },
  {
    time: "28:30",
    text: "really nice health climb that's happening right now. uh and basically they went and looked on GitHub. They",
  },
  {
    time: "28:36",
    text: "found the the you know most complex repositories. They found bug statements that are very clear uh and they found",
  },
  {
    time: "28:44",
    text: "ProQuest that actually solve those bug statements with unit tests and everything. So there is an existing",
  },
  {
    time: "28:49",
    text: "corpus on GitHub of tasks that that the AIS can can solve and you can also generate them. Those are not too hard to",
  },
  {
    time: "28:56",
    text: "to generate uh you know what's called synthetic uh data. Uh uh but but you're",
  },
  {
    time: "29:04",
    text: "right it's not infinitely scalable um because you you some human verifiers",
  },
  {
    time: "29:09",
    text: "still need to kind of look at the at the task but maybe the foundation models have found a way to have the synthetic",
  },
  {
    time: "29:14",
    text: "training go all the way right and then what's happening I think I think because what's happening is the foundation model companies are in some",
  },
  {
    time: "29:19",
    text: "cases they are hire they're actually hiring human experts to generate new training data. Yes. So they're actually hiring mathematicians and physicists and coders",
  },
  {
    time: "29:26",
    text: "to basically sit and you know they're they're hiring they're they're hiring human programmers putting them on the",
  },
  {
    time: "29:31",
    text: "cocaine. Yes. Um and having them probably coffee um uh and having them actually write code and",
  },
  {
    time: "29:37",
    text: "then and then write code in a way where there's a known result of the code running such that the this RO loop can be trained properly. That's right. And",
  },
  {
    time: "29:43",
    text: "then the other the other and then the other thing these companies are doing is as you said they're building systems where the software itself generates the",
  },
  {
    time: "29:49",
    text: "training data, generates the tests, generates the valid the validated results and and that's soal synthetic",
  },
  {
    time: "29:55",
    text: "training data. That's right. And but yeah, but but again those work in the very hard",
  },
  {
    time: "30:00",
    text: "domains. It works to some extent in the software domains and I think there's some transfer learning we can you can see the",
  },
  {
    time: "30:06",
    text: "reasoning work when it comes to you know tools like deep research and things like that but we're not making as fast as",
  },
  {
    time: "30:12",
    text: "progress in the in the more soft domain. So so say softer domains meaning like domains in which it's harder harder or",
  },
  {
    time: "30:20",
    text: "even impossible to actually verify correctness of of result in a sort of a deterministic factual grounded",
  },
  {
    time: "30:26",
    text: "non-controversial way. Like if you have a a chronic disease, you could you could have you know you have a POTS or uh you",
  },
  {
    time: "30:35",
    text: "know whatever EDS syndrome or and they're all they're all clusters and it's because it it is the domain of",
  },
  {
    time: "30:42",
    text: "abstraction. It is not as concrete as code and math and things like that. So I think there's still a long ways to go",
  },
  {
    time: "30:48",
    text: "there. Right. So sort of the more concrete the problem like it's the concretness of the problem that is the key variable not the",
  },
  {
    time: "30:53",
    text: "difficulty of the problem. Would that be a way to think about it? Yeah. Yeah. I think the the uh concreteness in a sense of can you get a",
  },
  {
    time: "31:00",
    text: "true or false ver verifiable right but like in any domain in any domain of human effort in which there's a verifiable answer we should expect",
  },
  {
    time: "31:06",
    text: "extremely rapid progress. Yes. Right. Yes. Absolutely. And I I think that's what we're saying. Right. And that and that for sure includes math. That for sure includes",
  },
  {
    time: "31:12",
    text: "physics for sure includes chemistry. For sure includes large areas of code. That's right. Right. What what else does that include",
  },
  {
    time: "31:17",
    text: "do you think? Bio like we're seeing with a protein genomic. Yeah. Okay. Right. Yeah. Yeah. Things like that. I think",
  },
  {
    time: "31:24",
    text: "some some areas of robotics, right? Um there's a clear outcome, right?",
  },
  {
    time: "31:30",
    text: "Uh but but it's not that many. I mean, surprisingly, well, it depends. Yeah, depends on your point of view.",
  },
  {
    time: "31:36",
    text: "That's some people might say that's a lot. Um so, uh and then um you you mentioned that we you mentioned the pace of improvement. So, what would you",
  },
  {
    time: "31:42",
    text: "expect from the pace of improvement going forward for this? I I think we're we're ripping on coding. Like I think I think it's just it's",
  },
  {
    time: "31:50",
    text: "going like I think it's going to be like what we're working on with with agent",
  },
  {
    time: "31:55",
    text: "floor right now um is by by next year we think you're going to be sitting instead of rep in front of replet and you're",
  },
  {
    time: "32:02",
    text: "shooting off multiple agents at a time. You're like planning a new feature. Um",
  },
  {
    time: "32:07",
    text: "so I I want you know social network on top of my storefront and another one is",
  },
  {
    time: "32:12",
    text: "like hey um refactor the database. Hey, in and you're running parallel agents.",
  },
  {
    time: "32:18",
    text: "So, you have five 10 agents kind of working in the background and they're merging the code and taking care of all of that, but you also have a really nice",
  },
  {
    time: "32:25",
    text: "interface on top of that that you're doing design and you're interacting with AI in a more creative way. Uh maybe",
  },
  {
    time: "32:30",
    text: "using visuals and charts and things like that. So, there's a multimodal angle of that of that interaction. So I think you",
  },
  {
    time: "32:37",
    text: "know creating software is going to be such an exciting uh area and and and I think that the lay",
  },
  {
    time: "32:45",
    text: "person will be as good as a what a senior software engineer that works at Google uh is today. So I think I think",
  },
  {
    time: "32:52",
    text: "that's happening very soon. Um but but you know I don't see them and be curious",
  },
  {
    time: "32:59",
    text: "about your point of view but like my experience between as as a sort of a you know on the let's say healthcare side or",
  },
  {
    time: "33:06",
    text: "more you know write me an essay side or more creative side haven't seen as much of a rapid improvement as what we're",
  },
  {
    time: "33:12",
    text: "seeing in code. So so I think I think code is going to go to the moon. Math is probably as well some some you know",
  },
  {
    time: "33:18",
    text: "scientific domains bio things like that those are are going to move really fast. Yeah. So there's this there's this",
  },
  {
    time: "33:24",
    text: "there's this weird dynamic see if you agree with this and Eric also curious your point of view on this like there's this weird dynamic that we have and we",
  },
  {
    time: "33:30",
    text: "have this in the office here a lot and I also have this with like the leading of entrepreneurs a lot which is this thing of like like wow this is the most amazing",
  },
  {
    time: "33:36",
    text: "technology ever and it's moving really fast and yet we're still like really disappointed um and like it's not moving",
  },
  {
    time: "33:41",
    text: "fast enough and like it's like maybe right on the verge of stalling out and like you know we should both be like hyper excited but also on the verge of",
  },
  {
    time: "33:48",
    text: "like slitting our wrists because like you know the gravy train is coming to an end, right? And and I always wonder it's like",
  },
  {
    time: "33:53",
    text: "you know on the one hand it's like okay like you know not all I don't know ladders go to the moon like just because something you know looks like it works",
  },
  {
    time: "33:59",
    text: "or you know doesn't mean it's going to you know be able to you're going to be able to scale it up and have it work you know to the fullest extent. Um uh you",
  },
  {
    time: "34:05",
    text: "know so like it's important to like recognize practical limits and not just extrapolate everything to infinity. Um on the other hand like you know we're",
  },
  {
    time: "34:11",
    text: "dealing with magic here that we I think probably all would have thought was impossible 5 years ago or certainly 10 years ago.",
  },
  {
    time: "34:16",
    text: "Like I I didn't you know look I I you know I got my CS degree in the late ' 80s early 90s. I I never I didn't think I would live to see any of this, right?",
  },
  {
    time: "34:22",
    text: "Like this is just amazing that this is actually happening in in in my lifetime. Um but but there's a huge bet on AGI,",
  },
  {
    time: "34:28",
    text: "right? like whether it's the foundation models uh I think you know now the entire US economy is sort of a bet on",
  },
  {
    time: "34:34",
    text: "AGI and and there are crucial questions to ask whether are we on track to AGI or",
  },
  {
    time: "34:40",
    text: "not because there are some ways that I can tell you it doesn't seem like we're on track to AGI because we uh because",
  },
  {
    time: "34:47",
    text: "there doesn't seem to be transfer learning across these domains that are that are you know significance right so",
  },
  {
    time: "34:53",
    text: "if we get a lot better at code we're not immediately getting better at like generalized reasoning we need to go",
  },
  {
    time: "34:59",
    text: "also you know get training data and create RL environment for bio or chemistry or physics or math or law or",
  },
  {
    time: "35:07",
    text: "so so and this this has been the sort of point of discussion now in the AI community after the Darkish and Richard",
  },
  {
    time: "35:14",
    text: "Sutton uh interview where uh you know Richard Sutton kind of poured this cold",
  },
  {
    time: "35:19",
    text: "water on the on the bitter lesson. So everyone was using this uh essay that he",
  },
  {
    time: "35:24",
    text: "wrote called the bitter lesson. The idea is that there are um infinitely scalable",
  },
  {
    time: "35:29",
    text: "ways of uh doing uh uh AI research and and and and anytime you can pour more",
  },
  {
    time: "35:37",
    text: "compute and more data and go more performance out you're just you know that's the ultimate way of getting to",
  },
  {
    time: "35:43",
    text: "AGI and some people you know interpreted that interview that perhaps he's",
  },
  {
    time: "35:50",
    text: "doubtful that even we're even on a on a bitter uh lessened path here and perhaps",
  },
  {
    time: "35:56",
    text: "the current training regime is actually very much the opposite in which we we are so dependent on human data and human",
  },
  {
    time: "36:03",
    text: "annotation and and all of that stuff. So I think the I I agree with you. I mean",
  },
  {
    time: "36:09",
    text: "as a company we're we're excited about where things are headed but but there's there's a question of like are we on",
  },
  {
    time: "36:15",
    text: "track to AGI or not and be curious what you think. So, so and you know Ilia I",
  },
  {
    time: "36:20",
    text: "think you know Ilioskcover makes a makes a specific form of this argument which is basically like we're just literally running out of training data. It's a fossil fuel argument right like if we",
  },
  {
    time: "36:27",
    text: "slurped all the training fundamentally we've slurped all the data off the internet that is where almost all the data is at this point. There's a little",
  },
  {
    time: "36:32",
    text: "bit more data that's in like you know private dark pool somewhere that we're going to go get but like we have it all and then right we're",
  },
  {
    time: "36:37",
    text: "we're in this business now trying to generate new data but generating new data is hard and expensive you know compared to just like slurping things",
  },
  {
    time: "36:42",
    text: "off the internet. So there are these arguments. Um you know having said that you know you get into definitional questions here really quick",
  },
  {
    time: "36:47",
    text: "which are kind of a rabbit hole but having said that like you mentioned transfer learning. So transfer learning is the ability of the machine to right",
  },
  {
    time: "36:52",
    text: "to be an expert in one domain and then and then generalize that into another domain. My answer to that is like have you met",
  },
  {
    time: "36:57",
    text: "people? Um and how many people do you know are able to do transfer learning?",
  },
  {
    time: "37:03",
    text: "Not many. Right. Well because there's quite the opposite actually. The nerdier they are in a certain domain the kind of",
  },
  {
    time: "37:09",
    text: "you know often they have blind spots. We joke about how everyone's just [ __ ] in one area or they make some like",
  },
  {
    time: "37:14",
    text: "massive mistake and and like don't trust them on this but on this other topic you know right? Yeah. Well and this is a well-known thing among like for example",
  },
  {
    time: "37:20",
    text: "public intellect. So this happens there's actually been whole books written about this on so-called public intellectuals. So you get these people who show up on TV and they're experts",
  },
  {
    time: "37:26",
    text: "and what happens is they're like an expert in economics right and then they show up on TV and they talk about politics and they don't know anything",
  },
  {
    time: "37:31",
    text: "about politics right or they don't know anything about like medicine or they don't know anything about the law or they don't know anything about",
  },
  {
    time: "37:37",
    text: "computers. You know, this is the Paul Gregman talking about how the internet's going to be no more significant than the fax machine. Facts. He's a brilliant economist. He has no",
  },
  {
    time: "37:43",
    text: "idea what a how a computer works. Is he a brilliant economist? Well, at one at one point at one point",
  },
  {
    time: "37:49",
    text: "at one point, let's get even if even if he's a brilliant Well, this is the thing like what does that mean? Like should a",
  },
  {
    time: "37:56",
    text: "brilliant economist be able to extrapolate, you know, the internet is is a good question. But um but the point being like even if he is a you know,",
  },
  {
    time: "38:02",
    text: "take any take anybody Oh, by the way, or like Ein like Einstein's like actually my favorite example. I think you'd agree",
  },
  {
    time: "38:07",
    text: "Einstein was a brilliant physicist. He was like a he was he was a Stalinist. Like he was just he was Yeah. He was a",
  },
  {
    time: "38:12",
    text: "socialist and he was a Stalinist and he was like he thought like Stalin was fantastic. Out still. Yeah. Okay. All right.",
  },
  {
    time: "38:18",
    text: "True socialism. All right. All right. Einstein, you know, I'll I'll",
  },
  {
    time: "38:24",
    text: "I'll take your word for it. But like once he got into politics, he was just like totally loopy or or you know, even right or wrong. It's just he just",
  },
  {
    time: "38:29",
    text: "sounded like all of a sudden like an undergraduate lunatic, like somebody in a dorm room. Like he there was no transfer learning from physics into",
  },
  {
    time: "38:35",
    text: "politics. like he he didn't listen right or wrong he didn't there was no there was clearly there was nothing new in his",
  },
  {
    time: "38:40",
    text: "political analysis it was the same wrote routine [ __ ] you get out of you know yeah so so in a way the",
  },
  {
    time: "38:45",
    text: "argument you're making is like we maybe already a human level AI I mean perhaps the definition of AGI is is is something",
  },
  {
    time: "38:52",
    text: "totally different is like above human level that something that totally generalizes across domains it's it's not something that we've seen",
  },
  {
    time: "38:58",
    text: "yeah like we've ideal yeah I was saying we we've we've and you know look we should we should shoot big but we we've idealized a a we've idealized a goal",
  },
  {
    time: "39:05",
    text: "um that may be idealized in a way that like number one it's just it it's it's like so far beyond what people can do that it's you're no longer it's no",
  },
  {
    time: "39:12",
    text: "longer relevant comparison to people and and usually AGI is defined as you know able to do everything better than a person can",
  },
  {
    time: "39:17",
    text: "and it's like well okay so if doing everything better than a person can it's like if a person can't do any transfer learning at all",
  },
  {
    time: "39:22",
    text: "right doing even a little little bit a marginal bit might might actually be better or it might not matter just",
  },
  {
    time: "39:27",
    text: "because no no human can do it and so therefore you just you just stack up the domains there's also this well-known phenomenon in AI with you know t",
  },
  {
    time: "39:33",
    text: "typically this works the other way which there's a phenomenon AI AI engineers always complain about and scientists always complain about which is the",
  },
  {
    time: "39:39",
    text: "definition of AI is always the next thing that that the machine can't do and so like the definition for of AI for a",
  },
  {
    time: "39:44",
    text: "long time was like can it beat humans at chess and then the minute it could beat humans at chess that was no longer AI that was",
  },
  {
    time: "39:49",
    text: "just like oh that's just like boring that's computer chess it became computer chess it's just like boring and now it's an app on your iPhone and",
  },
  {
    time: "39:54",
    text: "nobody nobody and nobody cares right and it's immediately then cheering test was the test and then we passed it and nobody",
  },
  {
    time: "40:00",
    text: "we blew this is a really big deal there was no celebration there was no parties That's exactly right. There was no for 80 years the",
  },
  {
    time: "40:06",
    text: "Turing test I mean they made a movie about it like the whole thing that was the thing and like we blew right through it and nobody even registered it. Nobody",
  },
  {
    time: "40:12",
    text: "cares. It gets no credit for it. We're just like ah it's still you know complete p piece of [ __ ] like right and so there's this thing where so",
  },
  {
    time: "40:18",
    text: "the AI scientists are are are used to complaining basically that they're that they're they're being they're always being judged against the next thing as",
  },
  {
    time: "40:24",
    text: "opposed to all the things they've already they've already solved. Um uh but but that's maybe the other side of it which is they're also putting",
  },
  {
    time: "40:29",
    text: "out for themselves um an unreasonable goal. an an unreasonable goal and then doing this sort of self flagagillation",
  },
  {
    time: "40:35",
    text: "kind of along the way and and and I I kind of wonder yeah I I wonder kind of which way that cuts. Yeah. Yeah. It's an interesting question",
  },
  {
    time: "40:41",
    text: "like I started thinking about this idea of like it doesn't matter whether it's truly AGI and the way I define AGI is",
  },
  {
    time: "40:48",
    text: "that you put in a AI system in any environment and efficiently learns right",
  },
  {
    time: "40:53",
    text: "um you know it doesn't have to have that much prior knowledge in order to kind of learn something but also can transfer that knowledge across different domains.",
  },
  {
    time: "41:00",
    text: "Um but you know we can get to like functional AGI and what functional AGI",
  },
  {
    time: "41:06",
    text: "is is just yeah collect data on every uh useful uh economic activity in uh in the",
  },
  {
    time: "41:12",
    text: "world today and train an LLM on top of that or train the same foundation model on top of that and and we we'll go we'll",
  },
  {
    time: "41:19",
    text: "target every sector economy and and you can automate a big part of labor that way. So I think I think yeah I think",
  },
  {
    time: "41:26",
    text: "we're on that track for sure. Right. um you tweeted after GBG5 came out that you were feeling the",
  },
  {
    time: "41:31",
    text: "diminishing returns. Yeah. What were you expecting and but and and what needs to be done? Do we need another breakthrough",
  },
  {
    time: "41:36",
    text: "to get back to the pace of growth or what are your thoughts there? I mean this this whole discussion is is sort of about that and and my feeling is",
  },
  {
    time: "41:42",
    text: "that uh you know GPT5 uh got good at verifiable domains. It didn't feel that",
  },
  {
    time: "41:49",
    text: "much better at anything else. the more human angle of it. It felt like it regressed and like you had this uh sort",
  },
  {
    time: "41:55",
    text: "of uh Reddit pitchfork uh sort of uh movement against against Sam and Open AI",
  },
  {
    time: "42:02",
    text: "because they felt like they lost a friend. Gupta felt a lot more human and closer uh whereas GT5 felt a lot more",
  },
  {
    time: "42:11",
    text: "robotic, you know, very in its head kind of trying to think through through everything. And um and so I I I would",
  },
  {
    time: "42:17",
    text: "have just expected like when we went from GP2 2 to 3, it was clear it was",
  },
  {
    time: "42:23",
    text: "getting a lot more human. It was uh a lot closer to our experience. It can you",
  },
  {
    time: "42:28",
    text: "can feel like it's actually all it gets me like there's something about it that understands the world better. Similarly",
  },
  {
    time: "42:34",
    text: "3 to four to five didn't feel like it was a better overall",
  },
  {
    time: "42:42",
    text: "being as it were. But is that is that is that is that a is the question there",
  },
  {
    time: "42:48",
    text: "like is it emotionality? Is it partly emotionality but but again partly like I",
  },
  {
    time: "42:53",
    text: "like to ask models like very controversial uh things. Um can it",
  },
  {
    time: "42:58",
    text: "reason through uh I don't know how deep we want to go here but like um what happened with",
  },
  {
    time: "43:06",
    text: "World Trade 7, right? Sure. It's an interesting question, right? Like I'm not I'm not putting out a",
  },
  {
    time: "43:13",
    text: "theory, but like it's interesting like how did it you know and and can it can it think through controversial questions",
  },
  {
    time: "43:20",
    text: "in the same way that it can go think through a coding problem and there",
  },
  {
    time: "43:25",
    text: "hasn't been any movement there like the all the reasoning and all of that stuff I haven't se and not just that you know",
  },
  {
    time: "43:30",
    text: "that's a cute example but like um co right like you know the origins of co",
  },
  {
    time: "43:36",
    text: "right you know go you know dig up GPT4 or other models and go to GPT5, you're not going to find",
  },
  {
    time: "43:43",
    text: "that much difference of okay, let's reason together. Let's try to figure out what was the origins of CO because it's still an unanswered question, you know,",
  },
  {
    time: "43:50",
    text: "and I don't see them making progress in that. I mean, you play a lot with them. Do you feel like I use it differently? I don't know, maybe I have different expectations. Um,",
  },
  {
    time: "43:56",
    text: "I I'm I the way I my main use case actually is sort of sort of PhD and everything at my beck and call. Um, and",
  },
  {
    time: "44:03",
    text: "so I'm I'm trying to get it to explain things to me more than I'm trying to like, you know, have conversations with it. Maybe maybe I'm just unusual with",
  },
  {
    time: "44:09",
    text: "that. But and that that that gets back well. So what I what I what I found specifically is uh a combination of like GPT5 Pro plus deep reasoning or like",
  },
  {
    time: "44:16",
    text: "Rock 4 heavy like the you know the the highest end models um u like that um you know they now basically generate 30 to",
  },
  {
    time: "44:23",
    text: "40 page you know essentially books on demand on any topic. Um and so anytime I get curious about something you just",
  },
  {
    time: "44:29",
    text: "take it maybe it's my version of it but it's something like I don't like a good here's a good example. um when when when a when an advanced economy puts a tariff",
  },
  {
    time: "44:36",
    text: "on on on a raw m you know on a raw material or on a finished good like who pays you know is it is it the consumer is it",
  },
  {
    time: "44:41",
    text: "the is it the importer is it the exporter or is it the producer and and this actually a very complicated it turns out very complicated question it's",
  },
  {
    time: "44:47",
    text: "a big big big thing that economists study a lot and it's just like okay who you know who pays and what I found like for that kind of thing is it's",
  },
  {
    time: "44:52",
    text: "outstanding well well but but it's outstanding at um sort of going out of the web getting information synthesizing it",
  },
  {
    time: "44:59",
    text: "correct it it gives me it gives me a synthesized 20 30 40 p basically tops out 40 p 40 40 pages of PDF. Yeah.",
  },
  {
    time: "45:05",
    text: "Um uh but I can get I can get up to 40 pages of PDF but it's a completely coherent and as far as I can tell for",
  },
  {
    time: "45:10",
    text: "everything I've cross-cheed a completely like it like world class like if I hired you know for a question like that if I",
  },
  {
    time: "45:16",
    text: "hired like a great you know econ posttock at Stanford who just like went out and did that work like it would",
  },
  {
    time: "45:21",
    text: "maybe be that good. Yeah. Um but then but then of course the significance is it's like it's like you know at least for this is true for many",
  },
  {
    time: "45:28",
    text: "domains you know kind of PhD and everything and so but but this is synthesizing knowledge not trying to create new knowledge.",
  },
  {
    time: "45:33",
    text: "Well but this this gets to the this sort of you know of course the you get into the angels dancing on the head of a pin thing which is like what what you know",
  },
  {
    time: "45:39",
    text: "what's the difference how many how much new knowledge ever actually is there anyway? What do you actually expect from people when you ask them questions? Um,",
  },
  {
    time: "45:46",
    text: "and so what what I'm looking for is like, yes, explain this to me in like the the the clearest, most sophisticated, most complex, most like",
  },
  {
    time: "45:52",
    text: "complete way that it's possible for somebody to, you know, for a real expert to be able to to to explain things to",
  },
  {
    time: "45:57",
    text: "me. Um, and that's what I use it for. And again, as far as I can tell from the crossing, like I'm getting, you know, like almost like basically 100 out of",
  },
  {
    time: "46:02",
    text: "100, like I don't even think I've had an issue in months where it's like had had a problem in it.",
  },
  {
    time: "46:08",
    text: "And it's like, yeah, you can say, yeah, synthesizing is supposed to create new information, but like it's it's generating a 40 p. He's basically",
  },
  {
    time: "46:13",
    text: "generating a 40-page book. That's amazing. That's like incredibly like fluid. It's, you know, it's it's it's it's you know,",
  },
  {
    time: "46:19",
    text: "the the logical coherence of the entire like it's it's a great writing. Like if if you if you evaluated an a a human",
  },
  {
    time: "46:26",
    text: 'author on it, you would say, "Wow, that\'s a great author." You know, do are people who write books, you know, creating new knowledge? Well, yeah.',
  },
  {
    time: "46:32",
    text: "Well, sort of not because a lot of what they're doing is building on everything that came before them is synthesizing a mind, but also like a book is a creative",
  },
  {
    time: "46:39",
    text: "accomplishment, right? And so, yeah, one of the thing I'm I'm I'm I'm interested in I'm hoping AI could help",
  },
  {
    time: "46:46",
    text: "us solve is just like how confusing the information ecosystem right now. You",
  },
  {
    time: "46:51",
    text: "know, everything feels like propaganda. Like it doesn't feel like you're getting real information from anywhere. So, I I really want an AI that could help me",
  },
  {
    time: "46:58",
    text: "reason from first principles about what's happening in the world for me to actually get real information. and and",
  },
  {
    time: "47:04",
    text: "maybe that's an unreasonable sort of ask of of the AI researchers, but but I don't think we're we have made any",
  },
  {
    time: "47:10",
    text: "progress there. So maybe I'm over focus. Yeah, maybe I'm over in being in my my line or maybe I'm over focused on ar arguing at people as opposed to um",
  },
  {
    time: "47:16",
    text: "trying to get as trying to get underline truth. But well here here's the thing I I do a lot with this is I just say like",
  },
  {
    time: "47:22",
    text: "take take a provocative point of view um and then steel man the position take your co thing steel so I often I often",
  },
  {
    time: "47:28",
    text: "pair these steel man the position that it was a lab leak um and steel man the position that it was natural origins um and and again like is this creativity",
  },
  {
    time: "47:34",
    text: "or not? I don't know. But like what comes back is like 30 pages each of like wow like that is like the most compelling case in the world I can",
  },
  {
    time: "47:40",
    text: "imagine with like every you know everything marshaled against it like the argument structured in like the most possible part of the reason that started",
  },
  {
    time: "47:45",
    text: "happening is because it stopped being taboo to talk about a human origin when it was taboo",
  },
  {
    time: "47:51",
    text: "the the AIS would like talk will you know talk down to like oh you're a conspiracy theorist and so yes uh so",
  },
  {
    time: "47:59",
    text: "there's a there's a you know period of time and so it takes something truly controversial and they actually they",
  },
  {
    time: "48:04",
    text: "they can't reason about it because of all RLHF and answers all the limitations and as as you know I won't pick no",
  },
  {
    time: "48:09",
    text: "specific ones here but like there there are certain certain big models that will still lecture you that you're a bad person for asking that",
  },
  {
    time: "48:14",
    text: "question but but you know like I just there some of them are just like really really open now to you know being able to do these things",
  },
  {
    time: "48:20",
    text: "um and then um uh yeah so um okay uh yeah so okay so yeah so there's this",
  },
  {
    time: "48:27",
    text: "yeah so so basically like ultimately what you're looking for like the ultimate thing would be if there's something that's like I don't I think",
  },
  {
    time: "48:34",
    text: "anybody's really defined this really well because it's not because again it's like the conventional all the conventional definitions of AGI are like",
  },
  {
    time: "48:39",
    text: "basically comparing to people. Yeah. And there there and there it's always like you know it's the conventional",
  },
  {
    time: "48:44",
    text: "explanations of of of um of uh of AGI always for me struck me a lot like the debate around like whether a",
  },
  {
    time: "48:50",
    text: "self-driving car works or not which is is does a self-driving car work because it's a perfect driver uh or does it work",
  },
  {
    time: "48:55",
    text: "because it is a is better than the human driver and better than the human driver I think is actually quite you know just",
  },
  {
    time: "49:00",
    text: "like with the the chess thing and the go thing. I actually think like that that that's like a real thing. And then and then and then and then there's the like",
  },
  {
    time: "49:05",
    text: "is it a perfect driver which is you know what they're obviously the the self-driving car companies are working for but then I think you're looking for",
  },
  {
    time: "49:11",
    text: "something beyond the perfect driver. You're looking for the car who like knows where to go. So I I I I'm of two minds, right? So one mind is the sort of",
  },
  {
    time: "49:18",
    text: "practical entrepreneur, right? Uh and I just I have so many toys to play with to build like stop AI progress",
  },
  {
    time: "49:25",
    text: "today and replet will continue to get better for the next 5 years. like there's so much we can do just on the",
  },
  {
    time: "49:30",
    text: "app uh app layer and the infrastructure layer. So you know I but but I think that will",
  },
  {
    time: "49:36",
    text: "you know the the foundation models will continue to get better as well and so it's it's a very exciting time in our industry. Um the other mind is more",
  },
  {
    time: "49:43",
    text: "academic because as a kid I've always been interested in the nature of consciousness, nature of intelligence. I",
  },
  {
    time: "49:49",
    text: "was always interested in AI and reading the literature there and I would point to the RL uh literature. So Richard",
  },
  {
    time: "49:56",
    text: "Soden, there's another guy I think co-founder of deep mind Shane Lag wrote wrote a paper trying to define what AGI",
  },
  {
    time: "50:02",
    text: "is. Um and in there I think that the definition of AI I think is the is the",
  },
  {
    time: "50:08",
    text: "original perhaps correct one which is uh efficient continual learning.",
  },
  {
    time: "50:14",
    text: "Okay. Like if you if you truly want to build an artificial general intelligence that you can drop in any domain, you can",
  },
  {
    time: "50:20",
    text: "drop in a car without that much prior knowledge about cars and within um you",
  },
  {
    time: "50:27",
    text: "know how long does it take a human to to learn how to drive you within months be able to drive a car really well, you",
  },
  {
    time: "50:33",
    text: "know, generalized skill sort of generalized skill acquisition, generalized understanding acquisition,",
  },
  {
    time: "50:39",
    text: "generalized reasoning acquisition. And I think that's the thing that will like truly change the world. That's the thing",
  },
  {
    time: "50:45",
    text: "that would give us a better understanding of of the human mind of human consciousness and that's the thing",
  },
  {
    time: "50:52",
    text: "that will like propel us to the next uh level of human civilization.",
  },
  {
    time: "50:57",
    text: "on a civilization level that's a really deep question but separ",
  },
  {
    time: "51:05",
    text: "but but there's an academic aspect of it that I'm really so what and what odds what if we're on if we're on Kelsey today what what odds do we place on that",
  },
  {
    time: "51:11",
    text: "I I I'm kind of bearish on on on true AGI breakthrough because",
  },
  {
    time: "51:17",
    text: "what we built is so useful and economically valuable uh so in a way",
  },
  {
    time: "51:24",
    text: "good enough good enough is the enemy Yeah. Yeah. Do do you remember that essay? Um,",
  },
  {
    time: "51:29",
    text: "worse is better. Worse is better. Worse is better. Worse is better. And and so there's like a local there's like a trap. There's like a local local maximum",
  },
  {
    time: "51:35",
    text: "trap. We're in a local maximum local maximum trap where it's because it's because it's good enough for so",
  },
  {
    time: "51:40",
    text: "much economically productive work. Yes. It relieves the pressure um in the system to create the generalized answer.",
  },
  {
    time: "51:46",
    text: "Yes. And and then you have the weirdos like Rich Sutton and others that are still trying to go that down that path and maybe they'll succeed,",
  },
  {
    time: "51:52",
    text: "right? Uh but there's enormous optimization energy behind the current thing that we're hell climbing on this",
  },
  {
    time: "51:57",
    text: "like local maximum. Right. Right. Right. And and the irony of it is everybody's worried about like the you know the gazillions of dollars going into building out all this stuff",
  },
  {
    time: "52:03",
    text: "and and so the the the most ironic thing in the world would be if the gazillions of dollars are going into the local maximum. That's right.",
  },
  {
    time: "52:09",
    text: "As as opposed to a counterfactual world in which they're going into solving the general problem. But but it's also potentially irrational. Like maybe the general",
  },
  {
    time: "52:15",
    text: "problem is actually you know not within our lifetimes. Who knows? Right. Um, h how much further do you think like do",
  },
  {
    time: "52:21",
    text: "you think we squeeze most of the juice out of out of LLMs in general then? Or are there any other research directions that you're particularly um excited",
  },
  {
    time: "52:28",
    text: "about? Well, that's the thing. I think the problem is there aren't that that many.",
  },
  {
    time: "52:34",
    text: "I I think the the the breakthroughs in RL are incredibly exciting, but we also knew about them now for like over 10",
  },
  {
    time: "52:40",
    text: "years where you marry generative uh systems with uh with tree search and things like that. Um but but there's a",
  },
  {
    time: "52:47",
    text: "lot more to go there and I think again the the the the original minds behind reinforcement learning are trying to go",
  },
  {
    time: "52:53",
    text: "down that path and try to kind of bootstrap intelligence from scratch. Uh Carmarmac is is going down that path as",
  },
  {
    time: "53:00",
    text: "as far as I understand Carmarmac you guys may be invested but the the you know they're they're not trying to go down the LLM path. So there are people",
  },
  {
    time: "53:07",
    text: "that are trying to do that but I'm not seeing a lot of progress or outcome there but I watch it kind of from far.",
  },
  {
    time: "53:13",
    text: "Although, you know, for all we know, it's already there's already a bot on X somewhere. You know, you know, you never know. It",
  },
  {
    time: "53:19",
    text: "might not be a big announcement. It might just be a you know, one day there's just like a bot on X that starts winning all the arguments. Yeah, it could be",
  },
  {
    time: "53:26",
    text: "or a code a user read and all of a sudden it's generating incredible software. Um,",
  },
  {
    time: "53:31",
    text: "okay. Let's uh let's spend our remaining minutes. Let's let's let's talk about you. So, uh so uh so how so yeah, take",
  },
  {
    time: "53:36",
    text: "us start from the beginning with your uh with your life and how how did you get how did you get from being born to being in Silicon Valley?",
  },
  {
    time: "53:42",
    text: "Okay. um in two minutes. Yeah, I'm just I'm joking. But yeah, I I got introduced to computers uh",
  },
  {
    time: "53:50",
    text: "very very early on. And so for whatever reason, so I was born in Aman, Jordan",
  },
  {
    time: "53:56",
    text: "and for whatever reason, my my dad who was just a government engineer at the time uh decided that computers were",
  },
  {
    time: "54:03",
    text: "important and he didn't have a lot of money took out of that, bought a computer. It was the first computer in",
  },
  {
    time: "54:09",
    text: "their in our neighborhood. first computer of anyone I know. And I just",
  },
  {
    time: "54:14",
    text: "one of my earliest memories I was 6 years old just watching my dad unpack this machine and sort of open up this",
  },
  {
    time: "54:20",
    text: "huge manual and kind of finger type CD LS MKDIR and like I would, you know, be",
  },
  {
    time: "54:27",
    text: "behind his shoulder and just like watching him, you know, type these commands and seeing the sort of machine",
  },
  {
    time: "54:33",
    text: "kind of respond and do exactly what he's asked it to do. Um, pop in Tylenol as your",
  },
  {
    time: "54:41",
    text: "Exactly. Autism activated. Of course, you have to.",
  },
  {
    time: "54:47",
    text: "You have to. Exactly. What kind of um what kind of computer was it? Uh it was uh an IBM as far as I",
  },
  {
    time: "54:56",
    text: "remember. It was IBM PC. What year was this? Uh 1993. 1993. Okay. So, it's DOS. So, did it",
  },
  {
    time: "55:02",
    text: "have Windows at that point or No, it didn't have Windows. Right before Windows. right before Windows, but I think Windows had been",
  },
  {
    time: "55:08",
    text: "out, but you would add you it was an add-on. You wouldn't boot it up. So, we I think we bought the disc",
  },
  {
    time: "55:13",
    text: "for uh for uh for Windows and you had to kind of uh bootloaded, you know, from",
  },
  {
    time: "55:18",
    text: "the disk and and it will open Windows and you can click around. It wasn't that interesting cuz there wasn't a lot on",
  },
  {
    time: "55:24",
    text: "it. So, a lot of time I just spend in DOSs and writing batch files and opening games and messing around with that. Um",
  },
  {
    time: "55:31",
    text: "but it wasn't until Visual Basic that I started. So like after Windows 95 that I",
  },
  {
    time: "55:36",
    text: "started making real software, right? Uh and the first idea I had was um I I",
  },
  {
    time: "55:42",
    text: "used to be a huge gamer. So I used I used to go to these uh Lang gaming cafes and play Counter Strike and I would go",
  },
  {
    time: "55:49",
    text: "there and you know the whole thing is full of computers but they don't use any software to run their business. M it was",
  },
  {
    time: "55:54",
    text: "just like people running around just like writing down your machine number, how much time you spend on it and how",
  },
  {
    time: "56:00",
    text: "much did you pay and kind of tapping your shoulders like hey you need to pay a little more for that. And I asked him like why don't you like just build a",
  },
  {
    time: "56:06",
    text: "piece of software that allows me to log in and have a time or whatever. And I was like yeah we don't know how to do that. And I was like okay I think I know",
  },
  {
    time: "56:13",
    text: "how to do that. So I spent I was like 12 or something like that. I spent like 2 years building that uh and then went out",
  },
  {
    time: "56:19",
    text: "and tried to sell it and was able to sell it uh and was making so much money. I remember McDonald's opened uh in",
  },
  {
    time: "56:26",
    text: "Jordan uh around the time when I was 13 14. I took my entire class to McDonald's. It was very expensive, but I",
  },
  {
    time: "56:32",
    text: "was balling it all this money and I was showing off um and uh and so that was",
  },
  {
    time: "56:39",
    text: "the first uh business that I uh created. And then when it came to and at the time",
  },
  {
    time: "56:46",
    text: "I started kind of learning about AI, you know, reading sci-fi and all of that stuff. And when it came time to go to",
  },
  {
    time: "56:53",
    text: "college, uh I didn't want to go to computer science because I felt like coding is on its way to get automated. I",
  },
  {
    time: "57:00",
    text: "remember using these um wizards. Do you remember wizards? Yes. Wizards basically. It's like extremely",
  },
  {
    time: "57:06",
    text: "crude early bots or that generate code. Yeah. Yeah. And I remember you could like, you know, type in a few things like here's",
  },
  {
    time: "57:12",
    text: "my project, here's what it does, whatever, and then click click click and just like scaffold a lot of code. I was like, oh, I think that's the future.",
  },
  {
    time: "57:18",
    text: "Like coding is such a it's almost yeah it's solved you know why why should I go into coding I was okay if AI can do",
  },
  {
    time: "57:25",
    text: "the code what should I do well someone needs to build and maintain the computers and so I went to the computer",
  },
  {
    time: "57:30",
    text: "engineering and and and did that for a while uh but then rediscovered my love",
  },
  {
    time: "57:35",
    text: "for for programming uh reading program essays on lisp and things like that and",
  },
  {
    time: "57:41",
    text: "uh started messing around with scheme and programming languages like that um but then I found it incredibly difficult",
  },
  {
    time: "57:47",
    text: "to just like learn different programming languages. I didn't have a laptop at the time. And so every time I go to like",
  },
  {
    time: "57:53",
    text: "wanting to learn Python or Java, I would go to the computer lab, download",
  },
  {
    time: "57:58",
    text: "gigabytes of software, try to set it up, type a little bit of code, try to run it, you know, run into missing DL issue",
  },
  {
    time: "58:06",
    text: "or and I was like, man, this is so primitive. Like at the time it was 2008",
  },
  {
    time: "58:13",
    text: "something like that you know we had uh Google Docs, we had Gmail, you could",
  },
  {
    time: "58:18",
    text: "like open the browser uh and partly thanks to you and be able to kind of uh",
  },
  {
    time: "58:24",
    text: "use software on the internet and I thought the web is the ultimate software platform like everything should go on",
  },
  {
    time: "58:30",
    text: "the web. Okay, who's building an online development environment, right? And and no one, right? And it felt like I w I",
  },
  {
    time: "58:35",
    text: "found like $100 bill on the, you know, on the floor of Grand Association. Like surely someone should be building this,",
  },
  {
    time: "58:42",
    text: "but no, no one was building this. And so I was like, okay, I'll I'll try to build it. And I got something done in like a",
  },
  {
    time: "58:49",
    text: "couple hours. Uh, which was a text box. You type in some JavaScript. We And there's a there's a button that says",
  },
  {
    time: "58:54",
    text: "eval. You click eval and evaluates. It shows you in a in an alert box, right? Right. So oneplus 1 2 I was like oh I",
  },
  {
    time: "59:02",
    text: "have a programming environment. I showed it to my friends people started using it. I added a few additional things like saving the program. I was like okay all",
  },
  {
    time: "59:09",
    text: "right this is there's there's a real idea here. People love it. And then again it took me two two or three years",
  },
  {
    time: "59:15",
    text: "to actually be able to build anything because you know the browser can only run JavaScript. And it took a",
  },
  {
    time: "59:21",
    text: "breakthrough at the time. Uh, Moisella had a research project called mcripton",
  },
  {
    time: "59:26",
    text: "that allowed you to uh compile different uh programming languages like C, C++",
  },
  {
    time: "59:32",
    text: "into JavaScript. And for the browser to be able to run something like Python, I",
  },
  {
    time: "59:37",
    text: "needed to compile C, Python to JavaScript. So I was the first to do it in the world. uh so built uh contributed",
  },
  {
    time: "59:44",
    text: "to that project and built a lot of the scaffolding around it and we uh my",
  },
  {
    time: "59:49",
    text: "friends and I compiled Python into JavaScript and I was like okay we did it for Python let's do it for Ruby let's do",
  },
  {
    time: "59:55",
    text: "it for Lo and that's how the emergence of the idea for replet came is that when you need a ripple you should get it you",
  },
  {
    time: "1:00:01",
    text: "should replet it and so ripple is is the most primitive programming environment possible so I added all these programming languages and again all this",
  },
  {
    time: "1:00:08",
    text: "time my friends were using it and excited about And I was on GitHub at the time and just",
  },
  {
    time: "1:00:14",
    text: "my standard thing is like when I make a piece of software is open source it. And so I was open sourcing all the things I",
  },
  {
    time: "1:00:19",
    text: "was you know years building just like this underlying infrastructure to be able to just run code in the browser",
  },
  {
    time: "1:00:25",
    text: "and then it went viral uh went viral in hacker news and it coincided with the",
  },
  {
    time: "1:00:31",
    text: "MOO era. So massively online courses Udacity was coming online Corsera and",
  },
  {
    time: "1:00:36",
    text: "and most famously Code Academy. Right. So, Code Academy uh was the first kind of website that allowed you to code in",
  },
  {
    time: "1:00:42",
    text: "the browser interactively and learn how to code. And they built a lot of it on my software that I was open sourcing all",
  },
  {
    time: "1:00:48",
    text: "the way from Jordan. And so, I remember seeing them on Hacker News and they were going super viral. I was like, \"Hey, that's, you know, I I recognize this.",
  },
  {
    time: "1:00:54",
    text: 'What are you using?" And so, I left the Hacker News comments. I was like, "Oh, you\'re using my my open source package." And so, they reached out to me. They uh',
  },
  {
    time: "1:01:01",
    text: 'they\'re like, "Hey, would like to hire you." I was like, "I\'m not interested. I I want to start a startup. I want to start this thing called Replet." and and',
  },
  {
    time: "1:01:07",
    text: 'they\'re like, "Well, no, you know, you should come work with us. We can we can do the same stuff." And I kept saying, "No." I was like, "Okay, I\'ll contract',
  },
  {
    time: "1:01:14",
    text: 'with you." They were paying me $12 an hour. I was really excited about it. Back from Oman. Um, but they came out to their to their',
  },
  {
    time: "1:01:21",
    text: "credit. They came out of Jordan to recruit me and spend a few a few days there. And then I, you know, I kept",
  },
  {
    time: "1:01:26",
    text: "saying no. And in the end, they gave me an offer I can't refuse. Um, and they got me an O1 visa. Came to the United",
  },
  {
    time: "1:01:32",
    text: "States. That's when you moved. So when when was the first cuz you were born what year to 1987",
  },
  {
    time: "1:01:37",
    text: "87. What was the first year that you could remember where you had the idea that you might not live your life in Jordan and that you might you might",
  },
  {
    time: "1:01:43",
    text: "actually move to the US? Uh when I watched Pirates of Silicon Valley. Is that right? Okay. Got it. All right. Uh maybe",
  },
  {
    time: "1:01:50",
    text: "98 or 99. I don't know when it came out. Okay. That might be a good place to Yeah. Is it worth telling the hacker story",
  },
  {
    time: "1:01:55",
    text: "because there's a version of the world where you didn't actually like if that changed maybe you wouldn't have gone to America. Right. Right. Yeah. So uh in in school I",
  },
  {
    time: "1:02:03",
    text: "was programming the whole time you so I I just want to start businesses. I just like I'm exploding with ideas all the",
  },
  {
    time: "1:02:08",
    text: "time. And like the reason Replet exists is because I have ideas all the time. I just want to go type on the computer and like build them. Um so I wasn't going to",
  },
  {
    time: "1:02:15",
    text: "school. It was like incredibly boring for me. Uh and part of the reason why Replet has a mobile app today is because",
  },
  {
    time: "1:02:21",
    text: "I always wanted to program under the desk just to do things. Um and so the at school they kept",
  },
  {
    time: "1:02:28",
    text: "failing me uh for attendance. you know, so I would get A's, but I just didn't show up and so they they would fail me.",
  },
  {
    time: "1:02:35",
    text: "And so I felt it was incredibly unfair. And all my friends were graduating now. This year was like 2011. I've been like",
  },
  {
    time: "1:02:41",
    text: "for 6 years in college. It should be like a three or four year. And I was like incredibly depressed. I really",
  },
  {
    time: "1:02:47",
    text: 'wanted to be in Silicon Valley. And so I was like, "Oh, what if I changed my',
  },
  {
    time: "1:02:53",
    text: 'grades?" There we go. The university database. And um and and',
  },
  {
    time: "1:02:59",
    text: "so I went into my parents uh uh basement",
  },
  {
    time: "1:03:05",
    text: "uh and uh implemented uh the polyphasic sleep. Are you familiar with that?",
  },
  {
    time: "1:03:10",
    text: "I I I I am uh Leonardo da Vinci's uh polyphysic sleep. I didn't hear from Ronaldo da",
  },
  {
    time: "1:03:16",
    text: "Vinci. I heard it from Seinfeld cuz uh there's an episode where John Kamemer goes on on poly sleep what 20 minutes every four",
  },
  {
    time: "1:03:23",
    text: "hours. 20 minutes every 24 hours. And yes, and this this somehow is going to work well. And it",
  },
  {
    time: "1:03:28",
    text: "Yeah. And and hacking, if you've ever done anything, as the meme goes, this this has never worked for anybody else, but it might",
  },
  {
    time: "1:03:33",
    text: "but it might work for me. Yes. And a lot of what hacking is is that",
  },
  {
    time: "1:03:38",
    text: "you're you're coming up with ideas for like finding certain security holes and like writing a script and then running",
  },
  {
    time: "1:03:43",
    text: "that script and that script will take like a 20 30 minutes to run and so you'll take that, you know, 20 30 minutes to sleep and go on. So I spent",
  },
  {
    time: "1:03:50",
    text: "two weeks just going mad like trying to hack into the university database and uh finally I found um a way I found a SQL",
  },
  {
    time: "1:03:58",
    text: "injection somewhere on the site uh and I found a way to like be able to edit the the records but I didn't want to risk",
  },
  {
    time: "1:04:05",
    text: "it. So I went to my neighbor who's going to the same school. Uh I think till this day no one caught him. But I went to him",
  },
  {
    time: "1:04:10",
    text: "and I said um hey uh I have this way to change grades like would you want to be my guinea pig? And I was honest about",
  },
  {
    time: "1:04:16",
    text: "it. I was like I'm not going to do it. are you open to doing? He's like, \"Yeah, yeah, yeah.\" They call",
  },
  {
    time: "1:04:22",
    text: "his human trials. This is how medicine works.",
  },
  {
    time: "1:04:27",
    text: "So, so we we went and and and uh we went and changed his grades and he he went and pulled his transcript and the you",
  },
  {
    time: "1:04:34",
    text: "know, the update wasn't wasn't there and went back to the basement. Well, turned out that I had access to the uh slave",
  },
  {
    time: "1:04:41",
    text: "database. I didn't have access to ambassador database. So, find a way through the network privilege escalation. It was an Oracle",
  },
  {
    time: "1:04:48",
    text: "database that had a vulnerability and then found the real database and then I just, you know, did it for myself. Uh,",
  },
  {
    time: "1:04:54",
    text: "changed the grades and went and pulled my scrcripts and sure enough it actually",
  },
  {
    time: "1:05:00",
    text: "changed. Went and bought the the the the gown, went to the graduation parties,",
  },
  {
    time: "1:05:07",
    text: "uh, did all that. We're graduating. Um, and then one day I'm at home. It's like",
  },
  {
    time: "1:05:13",
    text: "maybe 6:00 or 7:00 p.m. I get a you know the the telephone at home rings",
  },
  {
    time: "1:05:19",
    text: "ominous ominous ring Santa um hello and he's like hey this is the",
  },
  {
    time: "1:05:25",
    text: "university registration system and I knew the guy that run it. Uh he's like look you know we we we're having this",
  },
  {
    time: "1:05:31",
    text: "problem. The system's been down all day and it keeps coming back to your record. there's an anomaly in your record where",
  },
  {
    time: "1:05:38",
    text: "you're both pass you have a passing grade but you're also banned from that",
  },
  {
    time: "1:05:43",
    text: "uh final exam of subject I was like oh [ __ ] well turns out the database is not normalized so typically that when they",
  },
  {
    time: "1:05:50",
    text: "ban you from an exam the the grades resets to 35 out of 100 but apparently there's a boolean flag and by the way",
  },
  {
    time: "1:05:56",
    text: "all the column names in the database are single single letters that was the hardest thing is security by obscurity",
  },
  {
    time: "1:06:02",
    text: "right and turns out there's a flag that I didn't track so when when when when you go over attendance um uh when you don't",
  },
  {
    time: "1:06:10",
    text: "attend and they they they want to fail you, they they ban you from the final exam. So, I changed the grades and that",
  },
  {
    time: "1:06:15",
    text: "that that created uh an issue and brought down the system. So, they were calling me and I thought at the time I",
  },
  {
    time: "1:06:22",
    text: "was like, you know, I could I could potentially lie and I'll it'll be a huge issue or I just like I'll just I'll just",
  },
  {
    time: "1:06:30",
    text: "fess up. Yeah. So, I said, hey, listen, look, um yeah, I might know something about it. Hey, let me let me come uh",
  },
  {
    time: "1:06:36",
    text: "tomorrow and kind of talk to you about what happened. So, I go in and I open the door and it's the deans of all the",
  },
  {
    time: "1:06:43",
    text: "all the schools. It's a computer science computer. They were all working on it for like days because it's like it's",
  },
  {
    time: "1:06:48",
    text: "like it's a very computerheavy, you know, university and it was like a problem and they're all kind of really intrigued",
  },
  {
    time: "1:06:55",
    text: "about what happened. And so I pull up a whiteboard and started explaining what I did and and everyone was engaged. I gave",
  },
  {
    time: "1:07:01",
    text: "them a lecture basically. your oral exam for your PhD. This is great. They were they were they were really",
  },
  {
    time: "1:07:07",
    text: 'excited and uh and I think I it was endearing to them. I was like, "Oh, wow. This is a this is a very interesting',
  },
  {
    time: "1:07:12",
    text: 'problem." Um and then I was like, "Okay, great. Thank you." And I was like, "Hey, wait,',
  },
  {
    time: "1:07:19",
    text: "wait. We don't know what to do with you. Do we send you to jail? Do we",
  },
  {
    time: "1:07:24",
    text: 'And uh I was like, "Hey, we have to escalate to the university um uh president." and and he he was a great',
  },
  {
    time: "1:07:30",
    text: "man and I think uh he gave me a second chance in life and I went to him and I",
  },
  {
    time: "1:07:35",
    text: "uh you know I I explained the situation I said like I'm really frustrated. I need to graduate. I need to get on with my life. I've been here for six years",
  },
  {
    time: "1:07:42",
    text: "and I just can't sit in in in school the stuff I already know. I'm a really good programmer. Uh and and he gave me a",
  },
  {
    time: "1:07:50",
    text: "Spider-Man line at the time. was like with great power comes great responsibility and you have a great power and you know and it really",
  },
  {
    time: "1:07:55",
    text: "affected me and I think he he was right at the moment and and so he said well",
  },
  {
    time: "1:08:00",
    text: "we're going to let you go but you're going to have to help the system administrators secure the system",
  },
  {
    time: "1:08:06",
    text: "uh for the summer I was like happy to do it and I show up and all the programmers there hate me hate my gut%",
  },
  {
    time: "1:08:12",
    text: "and uh they they would lock me out like I would see them they would be outside I would knock on the door and nobody would listen it's like they don't want to let",
  },
  {
    time: "1:08:18",
    text: "me in I try to help them a little bit they theyen't and collaborative and so I was like all right whatever. Uh and so",
  },
  {
    time: "1:08:25",
    text: "it came time for me to actually graduate. It was the final project and one of the computer science dean came to",
  },
  {
    time: "1:08:32",
    text: "me and he said look I I need to call a favor. I was a big part of the reason we kind of let you go and we didn't kind of",
  },
  {
    time: "1:08:38",
    text: "prosecute you. Uh so I want you to work with me on the um on the final project",
  },
  {
    time: "1:08:43",
    text: "and it's going to be around security and hacking. I was like no I'm I'm done with that [ __ ] like I just want to I just",
  },
  {
    time: "1:08:49",
    text: "want to build programming environments and things like that. Uh and he's like no you have to do it. I was like okay.",
  },
  {
    time: "1:08:54",
    text: "So I I thought I' do something more productive. So I wrote a security scanner uh that was very proud of that that kind of crawls the different side",
  },
  {
    time: "1:09:01",
    text: "that tries to do SQL injection and all sorts of things. Um and actually my security scanner found another",
  },
  {
    time: "1:09:06",
    text: "vulnerability in the system. Amazing. And so I went to the defense and he's like you need to run this security",
  },
  {
    time: "1:09:12",
    text: "scanner live and show that there's a vulnerability. And I didn't understand what was going on at the time, but I just okay. So I gave the presentation",
  },
  {
    time: "1:09:20",
    text: "about how the system works and I was like, oh, let's run it. And it showed that there's security vulnerability. Okay, let's get let's try to get a",
  },
  {
    time: "1:09:25",
    text: "shell. So the system automatically runs all the security stuff and it gets you gets you a shell. And then the other",
  },
  {
    time: "1:09:33",
    text: "dean that turned out he was giving the mandate to secure the system. And now I started to realize I'm a pawn in some",
  },
  {
    time: "1:09:40",
    text: "kind of rivalry here. and and his his face turned red and he's like, \"No, it's",
  },
  {
    time: "1:09:46",
    text: 'impossible. You know, we secured the system. You\'re lying." I was like, "You',
  },
  {
    time: "1:09:51",
    text: "know, you're accusing me of lying.\" All right. What should we know? Should we know your um uh your salary or your",
  },
  {
    time: "1:09:58",
    text: 'password? What do you want me to look up? And I was like, "Yeah, I look up my password." So, I I look up his his password. Uh and it was like gibberish.',
  },
  {
    time: "1:10:05",
    text: "It was encrypted. And I was like, \"Oh, that's not my password. See, you're lying.\" I was like, \"Well, there's a decrypt function that the programmers",
  },
  {
    time: "1:10:10",
    text: 'put in there." So I I do decrypt and it shows his password. It was something embarrassing. I forgot I forgot what it',
  },
  {
    time: "1:10:17",
    text: "was. And so he gets up really angry, shakes my hand and leaves to change his password. Uh so that I I was able to",
  },
  {
    time: "1:10:24",
    text: "hack into the university another time. Luckily I I was able to graduate, gave them the software, they secured the",
  },
  {
    time: "1:10:30",
    text: "system. But um but yeah, later on I would realize that yeah, he wanted to",
  },
  {
    time: "1:10:35",
    text: "embarrass the other guy, which was why I was in the middle. Politics. Well, I think the the moral the moral of the story is if if you can",
  },
  {
    time: "1:10:40",
    text: "successfully hack into your school system and change your grade, you deserve the grade and you deserve to graduate. I I think so.",
  },
  {
    time: "1:10:46",
    text: "And and and just for any for any parents out there just children out there, you can just you can see you can site you can sight site me as the moral you can",
  },
  {
    time: "1:10:52",
    text: "site you can set out to me as the moral moral authority moral authority on this. One maybe lesson I think that is very",
  },
  {
    time: "1:10:58",
    text: "relevant for the AI age. Uh I think that the traditional sort of more conformous",
  },
  {
    time: "1:11:05",
    text: "path is paying less and less dividends and I think uh you know kids coming up",
  },
  {
    time: "1:11:10",
    text: "today should use all the tools available to be able to discover and chart their",
  },
  {
    time: "1:11:15",
    text: "own paths cuz I feel like just you know listening to the traditional advice and",
  },
  {
    time: "1:11:21",
    text: "doing the same things that people have always done is just not as it's not",
  },
  {
    time: "1:11:26",
    text: "working out as much as as we'd like. Thanks for coming on the podcast. Thank you, man. Fantastic.",
  },
  {
    time: "1:11:41",
    text: "Wow. Wow. Wow.",
  },
];

export default video3Transcripts;
